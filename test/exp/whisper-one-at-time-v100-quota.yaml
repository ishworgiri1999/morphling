apiVersion: "morphling.kubedl.io/v1alpha1"
kind: ProfilingExperiment
metadata:
  name: whispertiny-quota-v100
  namespace: fast-gshare-fn
  annotations:
    "fastgshare/vgpu_uuid": "GPU-c681a026-7f84-dafd-e970-6b191593230e"
    "fastgshare/allocation_type": "FASTPOD"
    "fastgshare/node_name": "i10se14"
spec:
  objective:
    type: maximize
    objectiveMetricName: qps
  algorithm:
    algorithmName: grid
  parallelism: 1
  maxNumTrials: 20
  clientTemplate:
    spec:
      template:
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: "node-role.kubernetes.io/master"
                        operator: "Exists"
          containers:
            - name: pi
              image: ishworgiri/morphling-http-client:faas
              env:
                - name: TF_CPP_MIN_LOG_LEVEL
                  value: "3"
                - name: MODEL_NAME
                  value: "Whisper-tiny"
                - name: LOCUST_NUM_USERS
                  value: "10"
                - name: LOCUST_SPAWN_RATE
                  value: "10"
                - name: LOCUST_RUN_TIME
                  value: "30"
                - name: LOCUST_LOCUSTFILE
                  value: "locustfile_httpuser.py"
                - name: LOCUST_METRICS_EXPORT
                  value: "true"
                - name: DCGM_ENDPOINT
                  value: "http://dcgm-exporter.fast-gshare.svc.cluster.local:9400/metrics"
                - name: FAIL_RATIO
                  value: "0.7"
                - name: PRINTLOG
                  value: "True"
              resources:
                requests:
                  cpu: 800m
                  memory: "1800Mi"
                limits:
                  cpu: 800m
                  memory: "1800Mi"
              command: ["python3"]
              args: ["morphling_client_locust.py"]

              imagePullPolicy: Always
          restartPolicy: Never
      backoffLimit: 1

  servicePodTemplate:
    template:
      spec:
        containers:
          - name: bert
            image: ishworgiri/whisper
            imagePullPolicy: Always #IfNotPresent
            ports:
              - containerPort: 8080
            readinessProbe:
              httpGet:
                path: /health
                port: 5000
              failureThreshold: 3
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 2
            livenessProbe:
              httpGet:
                path: /health
                port: 5000
              failureThreshold: 3
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 2
            volumeMounts:
              - name: "model-volume"
                mountPath: "/models/"
        volumes:
          - name: "model-volume"
            hostPath:
              path: "/models/"

  tunableParameters:
      - category: "env"
        parameters:
          - parameterType: discrete
            name: "GPU_QUOTA"
            feasibleSpace:
              list:
                - "0.5"
                - "1.0"
          - parameterType: discrete
            name: "GPU_MEMORY"
            feasibleSpace:
              list:
                - "2073741824"
          - parameterType: discrete
            name: "PREFFERED_GPU_TYPE"
            feasibleSpace:
              list:
                - "V100"
          - parameterType: discrete
            name: "REPLICA"
            feasibleSpace:
              list:
                - "1"
          - parameterType: discrete
            name: "GPU_SM"
            feasibleSpace:
              list:
                - "10"
                - "20"
                - "30"
                - "40"
                - "50"
                - "60"
                - "70"
                - "80"
                - "90"
                - "100"
apiVersion: "morphling.kubedl.io/v1alpha1"
kind: ProfilingExperiment

metadata:
  name: rnst-noquota-t1000
  namespace: fast-gshare-fn
  annotations:
    "fastgshare/vgpu_id": "GPU-bbc97af9-b22d-b2a7-24df-20ecae287dab"
    "fastgshare/allocation_type": "FASTPOD"
    "fastgshare/nodeName": "atschulz7"
spec:

  objective:
    type: maximize
    objectiveMetricName: qps
  algorithm:
    algorithmName: grid
  parallelism: 1
  maxNumTrials: 20
  clientTemplate:
    spec:
      template:
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: "node-role.kubernetes.io/master"
                        operator: "Exists"
          containers:
            - name: pi
              image: ishworgiri/morphling-http-client:faas
              env:
                - name: TF_CPP_MIN_LOG_LEVEL
                  value: "3"
                - name: MODEL_NAME
                  value: "MLPerf-FaaS-ResNet"
                - name: LOCUST_NUM_USERS
                  value: "10"
                - name: LOCUST_SPAWN_RATE
                  value: "10"
                - name: LOCUST_RUN_TIME
                  value: "30"
                - name: LOCUST_LOCUSTFILE
                  value: "locustfile_httpuser.py"
                - name: LOCUST_METRICS_EXPORT
                  value: "true"
                - name: DCGM_ENDPOINT
                  value: "http://dcgm-exporter.fast-gshare.svc.cluster.local:9400/metrics"
                - name: FAIL_RATIO
                  value: "0.3"
                - name: PRINTLOG
                  value: "True"
              resources:
                requests:
                  cpu: 800m
                  memory: "1800Mi"
                limits:
                  cpu: 800m
                  memory: "1800Mi"
              command: ["python3"]
              args: ["morphling_client_locust.py"]
              #command: [ "tail", "-f", "/dev/null" ]

              imagePullPolicy: Always
          restartPolicy: Never
          terminationGracePeriodSeconds: 1
      backoffLimit: 1

  servicePodTemplate:
    template:
      spec:
        containers:
          - name: resnet
            image: ishworgiri/resnet:pytorch
            imagePullPolicy: Always #IfNotPresent
            env:
              - name: MODEL_NAME
                value: "MLPerf-FaaS-ResNet"
            ports:
              - containerPort: 8080
            readinessProbe:
              tcpSocket:
                port: 5000
              initialDelaySeconds: 5
              periodSeconds: 10
            volumeMounts:
              - name: "model-volume"
                mountPath: "/models/"
                #command: [ "tail", "-f", "/dev/null" ]
        volumes:
          - name: "model-volume"
            hostPath:
              path: "/models/"

  tunableParameters:
    - category: "env"
      parameters:
        - parameterType: discrete
          name: "GPU_QUOTA"
          feasibleSpace:
            list:
              - "1.0"
        - parameterType: discrete
          name: "GPU_MEMORY"
          feasibleSpace:
            list:
              - "2073741824"
        - parameterType: discrete
          name: "PREFFERED_GPU_TYPE"
          feasibleSpace:
            list:
              - "V100"
        - parameterType: discrete
          name: "REPLICA"
          feasibleSpace:
            list:
              - "1"
        - parameterType: discrete
          name: "GPU_SM"
          feasibleSpace:
            list:
              - "5"
              - "10"
              - "15"
              - "20"
              - "25"
              - "30"
              - "35"
              - "40"
              - "45"
              - "50"
              - "55"
              - "60"
              - "65"
              - "70"
              - "75"
              - "80"
              - "85"
              - "90"
              - "95"
              - "100"

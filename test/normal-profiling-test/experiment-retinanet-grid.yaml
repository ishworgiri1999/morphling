apiVersion: "morphling.kubedl.io/v1alpha1"
kind: ProfilingExperiment
metadata:
  name: rtnt
spec:
  objective:
    type: maximize
    objectiveMetricName: qps
  algorithm:
    algorithmName: grid
  parallelism: 1
  maxNumTrials: 18
  clientTemplate:
    spec:
      template:
        spec:
          containers:
          - name: pi
            image: ishworgiri/morphling-http-client:demo
            env:
              - name: TF_CPP_MIN_LOG_LEVEL
                value: "3"
              - name: MODEL_NAME
                value: "MLPerf-FaaS-RetinaNet"
              - name: LOCUST_NUM_USERS
                value: "10"
              - name: LOCUST_SPAWN_RATE
                value: "10"
              - name: LOCUST_RUN_TIME
                value: "20"
              - name: LOCUST_LOCUSTFILE
                value: "locustfile_httpuser.py"
              - name: LOCUST_METRICS_EXPORT
                value: "true"
              - name: DCGM_ENDPOINT
                value: "http://dcgm-exporter.kube-system.svc.cluster.local:9400/metrics"
              - name: FAIL_RATIO
                value: "0.3"
              - name: PRINTLOG
                value: "True"
            resources:
              requests:
                cpu: 800m
                memory: "1800Mi"
              limits:
                cpu: 800m
                memory: "1800Mi"
            command: [ "python3" ]
            args: ["morphling_client_locust.py"]
            #command: [ "tail", "-f", "/dev/null" ]
    
            imagePullPolicy: Always
          restartPolicy: Never
      backoffLimit: 1

  servicePodTemplate:
    template:
      spec:
        containers:
          - name: resnet
            image: ishworgiri/mlperf-faas-retinanet
            imagePullPolicy: Always #IfNotPresent
            env:
              - name: MODEL_NAME
                value: "MLPerf-FaaS-RetinaNet"
            ports:
              - containerPort: 8080
            readinessProbe:
              tcpSocket:
                port: 5000
              initialDelaySeconds: 5
              periodSeconds: 10
            volumeMounts:
              - name: "model-volume"
                mountPath: "/models/"
                #command: [ "tail", "-f", "/dev/null" ]
        volumes:
          - name: "model-volume"
            hostPath:
              path: "/models/"

  tunableParameters:
    - category: "env"
      parameters:
        - parameterType: discrete
          name: "GPU_QUOTA"
          feasibleSpace:
            list:
              - "0.4"
              - "0.8"
        - parameterType: discrete
          name: "GPU_MEMORY"
          feasibleSpace:
            list:
              - "2073741824"
        #- parameterType: discrete
        #  name: "GPU_SM"
        #  feasibleSpace:
        #    list:
        #      - "40"
        #      - "60"
        #      - "80"
